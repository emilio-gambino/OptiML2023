{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code implemented with python 3.10\n",
    "# check whther cu116 or cu113 installable\n",
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOh9LOMB-DcF",
    "outputId": "430c6454-8381-414a-e2d2-e2070931c3fc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, resnet50\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import math\n",
    "from collections import namedtuple\n",
    "import time\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8I8d1egSLZ_",
    "outputId": "f99b6e27-78b8-499f-fbf6-946295b007f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Code used from https://blog.paperspace.com/writing-resnet-from-scratch-in-pytorch/\n",
    "def data_loader(data_dir,\n",
    "                batch_size,\n",
    "                random_seed=42,\n",
    "                valid_size=0.1,\n",
    "                shuffle=True,\n",
    "                test=False):\n",
    "\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "    # define transforms\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "\n",
    "    if test:\n",
    "        dataset = datasets.CIFAR10(\n",
    "          root=data_dir, train=False,\n",
    "          download=True, transform=transform,\n",
    "        )\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle\n",
    "        )\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "    # load the dataset\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    valid_dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=True,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "    return (train_loader, valid_loader)\n",
    "\n",
    "\n",
    "# CIFAR10 dataset\n",
    "batch_size = 256\n",
    "train_loader, valid_loader = data_loader(data_dir='./data',\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "test_loader = data_loader(data_dir='./data',\n",
    "                              batch_size=batch_size,\n",
    "                              test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "-zSe-Ti9MYme"
   },
   "outputs": [],
   "source": [
    "# https://github.com/JayPatwardhan/ResNet-PyTorch/blob/master/ResNet/ResNet.py\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "\n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "\n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "      identity = x.clone()\n",
    "\n",
    "      x = self.relu(self.batch_norm2(self.conv1(x)))\n",
    "      x = self.batch_norm2(self.conv2(x))\n",
    "\n",
    "      if self.i_downsample is not None:\n",
    "          identity = self.i_downsample(identity)\n",
    "      print(x.shape)\n",
    "      print(identity.shape)\n",
    "      x += identity\n",
    "      x = self.relu(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "\n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "\n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "BSUY-YAb6Bmq"
   },
   "outputs": [],
   "source": [
    "# Code inspired by https://github.com/xinyandai/gradient-quantization\n",
    "\n",
    "# Compressor\n",
    "class IdenticalCompressor(object):\n",
    "    def __init__(self, size=None, shape=None, args=None):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def compress(vec):\n",
    "        return vec.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def decompress(signature):\n",
    "        return signature\n",
    "\n",
    "class PSQuantizer():\n",
    "    def __init__(self, Compressor, parameters, args):\n",
    "        self.parameters = list(parameters)\n",
    "        self.num_layers = len(self.parameters)\n",
    "        self.compressors = list()\n",
    "        self.compressed_gradients = [list() for _ in range(self.num_layers)]\n",
    "        self.args = args\n",
    "        self.error_feedback = args.ef\n",
    "        self.two_phase = self.args.two_phase\n",
    "        for param in self.parameters:\n",
    "            param_size = param.flatten().shape[0]\n",
    "            self.compressors.append(\n",
    "                Compressor(param_size, param.shape, args) if param_size > 1000\n",
    "                else IdenticalCompressor()\n",
    "            )\n",
    "            if self.error_feedback:\n",
    "                param.error = [torch.zeros_like(param)\n",
    "                               for _ in range(args.num_users)]\n",
    "            if self.error_feedback and self.two_phase:\n",
    "                param.server_error = torch.zeros_like(param)\n",
    "\n",
    "    def record(self, user, epoch):\n",
    "        if self.args.scale == 'exp':\n",
    "            scale = (2 / (math.exp(-epoch) + 1) - 1)\n",
    "        else:\n",
    "            scale = float(self.args.scale)\n",
    "\n",
    "        for i, param in enumerate(self.parameters):\n",
    "            if self.error_feedback:\n",
    "                param.grad.data.add_(scale * param.error[user])\n",
    "                decompressed_g = self.compressors[i].decompress(\n",
    "                    self.compressors[i].compress(param.grad.data)\n",
    "                )\n",
    "                param.error[user].data = param.grad.data - decompressed_g\n",
    "            else:\n",
    "                decompressed_g = self.compressors[i].decompress(\n",
    "                    self.compressors[i].compress(param.grad.data)\n",
    "                )\n",
    "            self.compressed_gradients[i].append(decompressed_g)\n",
    "\n",
    "    def apply(self):\n",
    "        for i, param in enumerate(self.parameters):\n",
    "            g = torch.stack(self.compressed_gradients[i], dim=0).mean(dim=0)\n",
    "\n",
    "            # if compress gradient on two phase, i.e.,\n",
    "            # compress the sum of decompressed gradient\n",
    "            if self.two_phase:\n",
    "                if self.error_feedback:\n",
    "                    g.add_(param.server_error)\n",
    "                    decompressed_g = self.compressors[i].decompress(\n",
    "                        self.compressors[i].compress(g))\n",
    "                    param.server_error = g - decompressed_g\n",
    "                    g = decompressed_g\n",
    "                else:\n",
    "                    g = self.compressors[i].decompress(\n",
    "                        self.compressors[i].compress(g))\n",
    "\n",
    "            param.grad.data = g\n",
    "        for compressed in self.compressed_gradients:\n",
    "            compressed.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "1p4z8-cU4W_z"
   },
   "outputs": [],
   "source": [
    "# Code inspired by https://github.com/xinyandai/gradient-quantization\n",
    "class QSGDCompressor(object):\n",
    "    def __init__(self, size, shape, args):\n",
    "        self.random = args.random\n",
    "        self.bit = args.n_bit\n",
    "        c_dim = args.c_dim\n",
    "        assert self.bit > 0\n",
    "\n",
    "        self.cuda = not args.no_cuda\n",
    "        self.s = 2 ** self.bit\n",
    "        self.size = size\n",
    "        self.shape = shape\n",
    "\n",
    "\n",
    "        self.code_dtype = torch.int32\n",
    "\n",
    "\n",
    "    def compress(self, vec):\n",
    "        \"\"\"\n",
    "        :param vec: torch tensor\n",
    "        :return: norm, signs, quantized_intervals\n",
    "        \"\"\"\n",
    "        vec = vec.view(-1)\n",
    "        # norm = torch.norm(vec, dim=1, keepdim=True)\n",
    "        norm = torch.max(torch.abs(vec), dim=0, keepdim=True)[0]\n",
    "        normalized_vec = vec / norm\n",
    "\n",
    "        scaled_vec = torch.abs(normalized_vec) * self.s\n",
    "        l = torch.clamp(scaled_vec, 0, self.s-1).type(self.code_dtype)\n",
    "\n",
    "        if self.random:\n",
    "            # l[i] <- l[i] + 1 with probability |v_i| / ||v|| * s - l\n",
    "            probabilities = scaled_vec - l.type(torch.float32)\n",
    "            r = torch.rand(l.size())\n",
    "            if self.cuda:\n",
    "                r = r.cuda()\n",
    "            l[:] += (probabilities > r).type(self.code_dtype)\n",
    "\n",
    "        signs = torch.sign(vec) > 0\n",
    "        return [norm, signs.view(self.shape), l.view(self.shape)]\n",
    "\n",
    "    def decompress(self, signature):\n",
    "        [norm, signs, l] = signature\n",
    "        assert l.shape == signs.shape\n",
    "        scaled_vec = l.type(torch.float32) * (2 * signs.type(torch.float32) - 1)\n",
    "        compressed = (scaled_vec.view(-1)) * norm / self.s\n",
    "        return compressed.view(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "ZizQPHexTjCI"
   },
   "outputs": [],
   "source": [
    "# Code inspired by https://github.com/xinyandai/gradient-quantization\n",
    "def train(batch_size, nodes, model, device, train_loader, test_loader, optimizer, quantizer, epoch, criterion):\n",
    "    model.train()\n",
    "    num_users = nodes\n",
    "    train_data = list()\n",
    "    # here the real batch size is (num_users * batch_size)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "      #print(f'batch index {batch_idx}')\n",
    "      train_data.clear()\n",
    "\n",
    "      for user_id in range(num_users-1):\n",
    "          train_data.append((data[user_id*batch_size:(user_id+1)*batch_size],\n",
    "                               target[user_id*batch_size:(user_id+1)*batch_size]))\n",
    "      train_data.append((data[(num_users-1)*batch_size:],\n",
    "                           target[(num_users-1)*batch_size:]))\n",
    "\n",
    "      loss = one_iter(model, device, criterion, optimizer,\n",
    "                        quantizer, train_data, num_users, epoch=epoch)\n",
    "\n",
    "    print('Train Epoch: {} Done.\\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
    "\n",
    "\n",
    "def one_iter(model, device, loss_func, optimizer, quantizer, train_data, num_users, epoch):\n",
    "    assert num_users == len(train_data)\n",
    "    model.train()\n",
    "    user_gradients = [list() for _ in model.parameters()]\n",
    "    all_losses = []\n",
    "    for user_id in range(num_users):\n",
    "        optimizer.zero_grad()\n",
    "        _data, _target = train_data[user_id]\n",
    "        data, target = _data.to(device), _target.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_func(pred, target)\n",
    "        # print(loss)\n",
    "        all_losses.append(loss)\n",
    "        loss.backward()\n",
    "        quantizer.record(user_id, epoch=epoch)\n",
    "    quantizer.apply()\n",
    "    optimizer.step()\n",
    "    return torch.stack(all_losses).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "PPVrtTEzTvXE"
   },
   "outputs": [],
   "source": [
    "def run_model(num_epochs, batch_size, nodes, model, optimizer, quantizer, criterion):\n",
    "  for epoch in range(num_epochs):\n",
    "    train(batch_size, nodes, model, device, train_loader, test_loader, optimizer, quantizer, epoch, criterion)\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))\n",
    "\n",
    "  with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "oxf0NezO123p"
   },
   "outputs": [],
   "source": [
    "### Default model setup ###\n",
    "\n",
    "# args used for quantization with defaults set\n",
    "arguments = namedtuple('arguments', ['ef', 'two_phase', 'n_bit', 'c_dim', 'random', 'no_cuda', 'num_users', 'scale'])\n",
    "error_feedback = True\n",
    "two_phase = False\n",
    "random = True\n",
    "no_cuda = False\n",
    "c_dim = 0\n",
    "scale = 1\n",
    "\n",
    "# Other params\n",
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "learning_rate = 0.01\n",
    "\n",
    "# ResNet50\n",
    "model = ResNet50(num_classes, channels=3).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06c9QnaTu-qq",
    "outputId": "03320b4b-2a39-4199-c655-0fd7a6beb36c"
   },
   "outputs": [],
   "source": [
    "# Run model for 2 nodes and 8 quantization bits\n",
    "num_nodes = 2\n",
    "num_bits = 8\n",
    "batch_size = batch_size // num_nodes\n",
    "\n",
    "print(f'###########################################################################\\n')\n",
    "print(f'Running ResNet50 for {num_nodes} node(s) and {num_bits} quantization bits:')\n",
    "start = time.time()\n",
    "\n",
    "args = arguments(ef=error_feedback, two_phase=two_phase, n_bit=num_bits, c_dim=c_dim, random=random, no_cuda=no_cuda, num_users=num_nodes, scale=scale)\n",
    "quantizer = PSQuantizer(QSGDCompressor, model.parameters(), args)\n",
    "\n",
    "run_model(num_epochs, batch_size, num_nodes, model, optimizer, quantizer, criterion)\n",
    "end = time.time()\n",
    "print(f'Elapsed time: {(end - start) / 60} minutes')\n",
    "print(f'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model for 2 nodes and 4 quantization bits\n",
    "num_nodes = 2\n",
    "num_bits = 4\n",
    "batch_size = batch_size // num_nodes\n",
    "\n",
    "print(f'###########################################################################\\n')\n",
    "print(f'Running ResNet50 for {num_nodes} node(s) and {num_bits} quantization bits:')\n",
    "start = time.time()\n",
    "\n",
    "args = arguments(ef=error_feedback, two_phase=two_phase, n_bit=num_bits, c_dim=c_dim, random=random, no_cuda=no_cuda, num_users=num_nodes, scale=scale)\n",
    "quantizer = PSQuantizer(QSGDCompressor, model.parameters(), args)\n",
    "\n",
    "run_model(num_epochs, batch_size, num_nodes, model, optimizer, quantizer, criterion)\n",
    "end = time.time()\n",
    "print(f'Elapsed time: {(end - start) / 60} minutes')\n",
    "print(f'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model for 2 nodes and 2 quantization bits\n",
    "num_nodes = 2\n",
    "num_bits = 2\n",
    "batch_size = batch_size // num_nodes\n",
    "\n",
    "print(f'###########################################################################\\n')\n",
    "print(f'Running ResNet50 for {num_nodes} node(s) and {num_bits} quantization bits:')\n",
    "start = time.time()\n",
    "\n",
    "args = arguments(ef=error_feedback, two_phase=two_phase, n_bit=num_bits, c_dim=c_dim, random=random, no_cuda=no_cuda, num_users=num_nodes, scale=scale)\n",
    "quantizer = PSQuantizer(QSGDCompressor, model.parameters(), args)\n",
    "\n",
    "run_model(num_epochs, batch_size, num_nodes, model, optimizer, quantizer, criterion)\n",
    "end = time.time()\n",
    "print(f'Elapsed time: {(end - start) / 60} minutes')\n",
    "print(f'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run baseline model for 2 nodes (i.e. 32 bits, no quantization)\n",
    "num_nodes = 2\n",
    "num_bits = 32\n",
    "error_feedback = False\n",
    "batch_size = batch_size // num_nodes\n",
    "\n",
    "print(f'###########################################################################\\n')\n",
    "print(f'Running ResNet50 for {num_nodes} node(s) and {num_bits} quantization bits:')\n",
    "start = time.time()\n",
    "\n",
    "args = arguments(ef=error_feedback, two_phase=two_phase, n_bit=num_bits, c_dim=c_dim, random=random, no_cuda=no_cuda, num_users=num_nodes, scale=scale)\n",
    "quantizer = PSQuantizer(QSGDCompressor, model.parameters(), args)\n",
    "\n",
    "run_model(num_epochs, batch_size, num_nodes, model, optimizer, quantizer, criterion)\n",
    "end = time.time()\n",
    "print(f'Elapsed time: {(end - start) / 60} minutes')\n",
    "print(f'\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
