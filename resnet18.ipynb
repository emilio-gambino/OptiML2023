{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-gzzBsCY6hm",
        "outputId": "388963ed-e951-4868-9251-da2deef13949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from collections import namedtuple\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import math\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loader(data_dir,\n",
        "                batch_size,\n",
        "                random_seed=42,\n",
        "                valid_size=0.1,\n",
        "                shuffle=True,\n",
        "                test=False):\n",
        "\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010],\n",
        "    )\n",
        "\n",
        "    # define transforms\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize((224,224)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "    ])\n",
        "\n",
        "    if test:\n",
        "        dataset = datasets.CIFAR10(\n",
        "          root=data_dir, train=False,\n",
        "          download=True, transform=transform,\n",
        "        )\n",
        "\n",
        "        data_loader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=batch_size, shuffle=shuffle\n",
        "        )\n",
        "\n",
        "        return data_loader\n",
        "\n",
        "    # load the dataset\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=transform,\n",
        "    )\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(42)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "\n",
        "# CIFAR10 dataset\n",
        "train_loader, valid_loader = data_loader(data_dir='./data',\n",
        "                                         batch_size=128)\n",
        "\n",
        "test_loader = data_loader(data_dir='./data',\n",
        "                              batch_size=128,\n",
        "                              test=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyw1XBM5ZAzu",
        "outputId": "21deb4f6-bd28-40eb-f817-b177313247cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 70153144.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Residual block"
      ],
      "metadata": {
        "id": "uNYADUIfZFpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels),\n",
        "                        nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(\n",
        "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
        "                        nn.BatchNorm2d(out_channels))\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "1fRKsGwYZI7Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resnet\n"
      ],
      "metadata": {
        "id": "uh12IF_BZOTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes = 10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "                        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU())\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
        "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
        "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
        "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "UZlc6llWZNWj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model resnet18"
      ],
      "metadata": {
        "id": "tCdX43GbZR9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18(num_classes=10):\n",
        "    return ResNet(ResidualBlock, [2, 2, 2, 2], num_classes=num_classes)"
      ],
      "metadata": {
        "id": "65FqmgxvZRcT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Quantization"
      ],
      "metadata": {
        "id": "592FQX0hZfYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compressor\n",
        "class IdenticalCompressor(object):\n",
        "    def __init__(self, size=None, shape=None, args=None):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def compress(vec):\n",
        "        return vec.clone()\n",
        "\n",
        "    @staticmethod\n",
        "    def decompress(signature):\n",
        "        return signature\n",
        "\n",
        "class PSQuantizer():\n",
        "    def __init__(self, Compressor, parameters, args):\n",
        "        self.parameters = list(parameters)\n",
        "        self.num_layers = len(self.parameters)\n",
        "        self.compressors = list()\n",
        "        self.compressed_gradients = [list() for _ in range(self.num_layers)]\n",
        "        self.args = args\n",
        "        self.error_feedback = args.ef\n",
        "        self.two_phase = self.args.two_phase\n",
        "        for param in self.parameters:\n",
        "            param_size = param.flatten().shape[0]\n",
        "            self.compressors.append(\n",
        "                Compressor(param_size, param.shape, args) if param_size > 1000\n",
        "                else IdenticalCompressor()\n",
        "            )\n",
        "            if self.error_feedback:\n",
        "                param.error = [torch.zeros_like(param)\n",
        "                               for _ in range(args.num_users)]\n",
        "            if self.error_feedback and self.two_phase:\n",
        "                param.server_error = torch.zeros_like(param)\n",
        "\n",
        "    def record(self, user, epoch):\n",
        "        if self.args.scale == 'exp':\n",
        "            scale = (2 / (math.exp(-epoch) + 1) - 1)\n",
        "        else:\n",
        "            scale = float(self.args.scale)\n",
        "\n",
        "        for i, param in enumerate(self.parameters):\n",
        "            if self.error_feedback:\n",
        "                param.grad.data.add_(scale * param.error[user])\n",
        "                decompressed_g = self.compressors[i].decompress(\n",
        "                    self.compressors[i].compress(param.grad.data)\n",
        "                )\n",
        "                param.error[user].data = param.grad.data - decompressed_g\n",
        "            else:\n",
        "                decompressed_g = self.compressors[i].decompress(\n",
        "                    self.compressors[i].compress(param.grad.data)\n",
        "                )\n",
        "            self.compressed_gradients[i].append(decompressed_g)\n",
        "\n",
        "    def apply(self):\n",
        "        for i, param in enumerate(self.parameters):\n",
        "            g = torch.stack(self.compressed_gradients[i], dim=0).mean(dim=0)\n",
        "\n",
        "            # if compress gradient on two phase, i.e.,\n",
        "            # compress the sum of decompressed gradient\n",
        "            if self.two_phase:\n",
        "                if self.error_feedback:\n",
        "                    g.add_(param.server_error)\n",
        "                    decompressed_g = self.compressors[i].decompress(\n",
        "                        self.compressors[i].compress(g))\n",
        "                    param.server_error = g - decompressed_g\n",
        "                    g = decompressed_g\n",
        "                else:\n",
        "                    g = self.compressors[i].decompress(\n",
        "                        self.compressors[i].compress(g))\n",
        "\n",
        "            param.grad.data = g\n",
        "        for compressed in self.compressed_gradients:\n",
        "            compressed.clear()"
      ],
      "metadata": {
        "id": "vHdmw_eIZedm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class QSGDCompressor(object):\n",
        "    def __init__(self, size, shape, args):\n",
        "        self.random = args.random\n",
        "        self.bit = args.n_bit\n",
        "        c_dim = args.c_dim\n",
        "        assert self.bit > 0\n",
        "\n",
        "        self.cuda = not args.no_cuda\n",
        "        self.s = 2 ** self.bit\n",
        "        self.size = size\n",
        "        self.shape = shape\n",
        "\n",
        "\n",
        "        self.code_dtype = torch.int32\n",
        "\n",
        "\n",
        "    def compress(self, vec):\n",
        "        \"\"\"\n",
        "        :param vec: torch tensor\n",
        "        :return: norm, signs, quantized_intervals\n",
        "        \"\"\"\n",
        "        vec = vec.view(-1)\n",
        "        # norm = torch.norm(vec, dim=1, keepdim=True)\n",
        "        norm = torch.max(torch.abs(vec), dim=0, keepdim=True)[0]\n",
        "        normalized_vec = vec / norm\n",
        "\n",
        "        scaled_vec = torch.abs(normalized_vec) * self.s\n",
        "        l = torch.clamp(scaled_vec, 0, self.s-1).type(self.code_dtype)\n",
        "\n",
        "        if self.random:\n",
        "            # l[i] <- l[i] + 1 with probability |v_i| / ||v|| * s - l\n",
        "            probabilities = scaled_vec - l.type(torch.float32)\n",
        "            r = torch.rand(l.size())\n",
        "            if self.cuda:\n",
        "                r = r.cuda()\n",
        "            l[:] += (probabilities > r).type(self.code_dtype)\n",
        "\n",
        "        signs = torch.sign(vec) > 0\n",
        "        return [norm, signs.view(self.shape), l.view(self.shape)]\n",
        "\n",
        "    def decompress(self, signature):\n",
        "        [norm, signs, l] = signature\n",
        "        assert l.shape == signs.shape\n",
        "        scaled_vec = l.type(torch.float32) * (2 * signs.type(torch.float32) - 1)\n",
        "        compressed = (scaled_vec.view(-1)) * norm / self.s\n",
        "        return compressed.view(self.shape)"
      ],
      "metadata": {
        "id": "SVM1TF-eZk0Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Early stoppage"
      ],
      "metadata": {
        "id": "NTDB_v8_cDnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')  # save checkpoint\n",
        "        self.val_loss_min = val_loss\n"
      ],
      "metadata": {
        "id": "vZRdtmruYcGy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Validation code"
      ],
      "metadata": {
        "id": "-TEIcYEIaD3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch, nodes_number, quantizer):\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "        Run one train epoch\n",
        "    \"\"\"\n",
        "\n",
        "    # switch to train mode\n",
        "    nodes = nodes_number\n",
        "\n",
        "    lossNodes = []\n",
        "\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "\n",
        "\n",
        "        input_var, target = input.cuda(), target.cuda()\n",
        "\n",
        "\n",
        "        images, labels = torch.chunk(input_var, nodes), torch.chunk(target, nodes)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "        for node in range(nodes):\n",
        "          outputnode = model(images[node])\n",
        "          lossNode = criterion(outputnode, labels[node])\n",
        "          lossNodes.append(lossNode)\n",
        "\n",
        "          lossNode.backward()\n",
        "          quantizer.record(node, epoch=epoch)\n",
        "\n",
        "        quantizer.apply()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    loss_values = [loss.item() for loss in lossNodes]\n",
        "    loss_value = sum(loss_values) / len(loss_values)\n",
        "    print ('Epoch [{}/{}],  Total loss : {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, loss_value ))\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        losses = []\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)  # Compute validation loss\n",
        "            losses.append(loss.item())\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "\n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))\n",
        "\n",
        "    # Calculate average validation loss\n",
        "    average_validation_loss = sum(losses) / len(losses)\n",
        "    return average_validation_loss\n",
        "\n",
        "    # Early stopping check\n"
      ],
      "metadata": {
        "id": "qwU7CjGMaDTc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zrLOK3lAaa14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting Hyperparameters"
      ],
      "metadata": {
        "id": "_Tvt3wCZaMgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Default model setup ###\n",
        "num_classes = 10\n",
        "num_epochs = 40\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "# args used for quantization with defaults set\n",
        "arguments = namedtuple('arguments', ['ef', 'two_phase', 'n_bit', 'c_dim', 'random', 'no_cuda', 'num_users', 'scale'])\n",
        "error_feedback = True\n",
        "two_phase = False\n",
        "random = True\n",
        "no_cuda = False\n",
        "c_dim = 0\n",
        "scale = 'exp'\n",
        "\n"
      ],
      "metadata": {
        "id": "OosIQqeMcZny"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Emilien"
      ],
      "metadata": {
        "id": "5SvNpgFwalKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 0\n",
        "for p in model.parameters():\n",
        "  n += len(p.view(-1))\n",
        "print(n)\n",
        "norm = n * 32\n",
        "q = 8\n",
        "res = 32 + n + n * q\n",
        "print(\"8 bits : \" + str(norm/res))\n",
        "q = 4\n",
        "res = 32 + n + n * q\n",
        "print(\"4 bits : \" + str(norm/res))\n",
        "q = 2\n",
        "res = 32 + n + n * q\n",
        "print(\"2 bits : \" + str(norm/res))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJK8Kii5agI-",
        "outputId": "7fa73b5a-0967-4b33-c270-c30320394429"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11186442\n",
            "8 bits : 3.5555544254400737\n",
            "4 bits : 6.39999633842677\n",
            "2 bits : 10.666656495633797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline"
      ],
      "metadata": {
        "id": "CRjn6gvuxjqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2 nodes 32 bits\n",
        "\n",
        "num_nodes = 2\n",
        "num_bits = 32\n",
        "\n",
        "# Model\n",
        "model = resnet18(num_classes).to(device)\n",
        "\n",
        "#Early stopping\n",
        "early_stopping = EarlyStopping(patience=17, verbose=True)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f'###########################################################################\\n')\n",
        "print(f'Running Resnet18 for {num_nodes} node(s) and {num_bits} quantization bits:')\n",
        "start = time.time()\n",
        "\n",
        "args = arguments(ef=error_feedback, two_phase=two_phase, n_bit=num_bits, c_dim=c_dim, random=random, no_cuda=no_cuda, num_users=num_nodes, scale=scale)\n",
        "quantizer = PSQuantizer(QSGDCompressor, model.parameters(), args)\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    average_validation_loss = train(train_loader, model, criterion, optimizer, epoch, num_nodes,  quantizer)\n",
        "\n",
        "    early_stopping(average_validation_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(f'Elapsed time: {(end - start) / 60} minutes')\n",
        "print(f'\\n\\n')\n",
        "# initialize the model\n",
        "model = resnet18(num_classes).to(device)\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "\n"
      ],
      "metadata": {
        "id": "ac3hgotwxnNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 nodes 2 bits"
      ],
      "metadata": {
        "id": "ElL45vVmascu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2 nodes 2 bits\n",
        "\n",
        "num_nodes = 2\n",
        "num_bits = 2\n",
        "# Model\n",
        "model = resnet18(num_classes).to(device)\n",
        "\n",
        "#Early stopping\n",
        "early_stopping = EarlyStopping(patience=15, verbose=True)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f'###########################################################################\\n')\n",
        "print(f'Running Resnet18 for {num_nodes} node(s) and {num_bits} quantization bits:')\n",
        "start = time.time()\n",
        "\n",
        "args = arguments(ef=error_feedback, two_phase=two_phase, n_bit=num_bits, c_dim=c_dim, random=random, no_cuda=no_cuda, num_users=num_nodes, scale=scale)\n",
        "quantizer = PSQuantizer(QSGDCompressor, model.parameters(), args)\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    average_validation_loss = train(train_loader, model, criterion, optimizer, epoch, num_nodes,  quantizer)\n",
        "\n",
        "    early_stopping(average_validation_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(f'Elapsed time: {(end - start) / 60} minutes')\n",
        "print(f'\\n\\n')\n",
        "# initialize the model\n",
        "model = resnet18(num_classes).to(device)\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-6nMHE8aro7",
        "outputId": "f7783263-194d-4703-deaa-b8a996e68d88"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###########################################################################\n",
            "\n",
            "Running Resnet18 for 2 node(s) and 2 quantization bits:\n",
            "Epoch [1/40],  Total loss : 1.4854\n",
            "Accuracy of the network on the 5000 validation images: 59.96 %\n",
            "Validation loss decreased (inf --> 1.114754).  Saving model ...\n",
            "Epoch [2/40],  Total loss : 0.9264\n",
            "Accuracy of the network on the 5000 validation images: 72.7 %\n",
            "Validation loss decreased (1.114754 --> 0.762367).  Saving model ...\n",
            "Epoch [3/40],  Total loss : 0.6816\n",
            "Accuracy of the network on the 5000 validation images: 77.02 %\n",
            "Validation loss decreased (0.762367 --> 0.671238).  Saving model ...\n",
            "Epoch [4/40],  Total loss : 0.5381\n",
            "Accuracy of the network on the 5000 validation images: 79.84 %\n",
            "Validation loss decreased (0.671238 --> 0.573482).  Saving model ...\n",
            "Epoch [5/40],  Total loss : 0.4405\n",
            "Accuracy of the network on the 5000 validation images: 81.06 %\n",
            "Validation loss decreased (0.573482 --> 0.564173).  Saving model ...\n",
            "Epoch [6/40],  Total loss : 0.3505\n",
            "Accuracy of the network on the 5000 validation images: 81.62 %\n",
            "Validation loss decreased (0.564173 --> 0.542465).  Saving model ...\n",
            "Epoch [7/40],  Total loss : 0.2781\n",
            "Accuracy of the network on the 5000 validation images: 81.02 %\n",
            "EarlyStopping counter: 1 out of 15\n",
            "Epoch [8/40],  Total loss : 0.2145\n",
            "Accuracy of the network on the 5000 validation images: 82.48 %\n",
            "EarlyStopping counter: 2 out of 15\n",
            "Epoch [9/40],  Total loss : 0.1644\n",
            "Accuracy of the network on the 5000 validation images: 80.64 %\n",
            "EarlyStopping counter: 3 out of 15\n",
            "Epoch [10/40],  Total loss : 0.1220\n",
            "Accuracy of the network on the 5000 validation images: 82.24 %\n",
            "EarlyStopping counter: 4 out of 15\n",
            "Epoch [11/40],  Total loss : 0.0929\n",
            "Accuracy of the network on the 5000 validation images: 82.6 %\n",
            "EarlyStopping counter: 5 out of 15\n",
            "Epoch [12/40],  Total loss : 0.0795\n",
            "Accuracy of the network on the 5000 validation images: 83.06 %\n",
            "EarlyStopping counter: 6 out of 15\n",
            "Epoch [13/40],  Total loss : 0.0643\n",
            "Accuracy of the network on the 5000 validation images: 83.16 %\n",
            "EarlyStopping counter: 7 out of 15\n",
            "Epoch [14/40],  Total loss : 0.0490\n",
            "Accuracy of the network on the 5000 validation images: 83.9 %\n",
            "EarlyStopping counter: 8 out of 15\n",
            "Epoch [15/40],  Total loss : 0.0338\n",
            "Accuracy of the network on the 5000 validation images: 82.84 %\n",
            "EarlyStopping counter: 9 out of 15\n",
            "Epoch [16/40],  Total loss : 0.0282\n",
            "Accuracy of the network on the 5000 validation images: 83.7 %\n",
            "EarlyStopping counter: 10 out of 15\n",
            "Epoch [17/40],  Total loss : 0.0247\n",
            "Accuracy of the network on the 5000 validation images: 83.58 %\n",
            "EarlyStopping counter: 11 out of 15\n",
            "Epoch [18/40],  Total loss : 0.0192\n",
            "Accuracy of the network on the 5000 validation images: 85.08 %\n",
            "EarlyStopping counter: 12 out of 15\n",
            "Epoch [19/40],  Total loss : 0.0111\n",
            "Accuracy of the network on the 5000 validation images: 84.46 %\n",
            "EarlyStopping counter: 13 out of 15\n",
            "Epoch [20/40],  Total loss : 0.0068\n",
            "Accuracy of the network on the 5000 validation images: 85.58 %\n",
            "EarlyStopping counter: 14 out of 15\n",
            "Epoch [21/40],  Total loss : 0.0026\n",
            "Accuracy of the network on the 5000 validation images: 86.22 %\n",
            "Validation loss decreased (0.542465 --> 0.532335).  Saving model ...\n",
            "Epoch [22/40],  Total loss : 0.0023\n",
            "Accuracy of the network on the 5000 validation images: 86.38 %\n",
            "Validation loss decreased (0.532335 --> 0.488898).  Saving model ...\n",
            "Epoch [23/40],  Total loss : 0.0020\n",
            "Accuracy of the network on the 5000 validation images: 86.7 %\n",
            "Validation loss decreased (0.488898 --> 0.480284).  Saving model ...\n",
            "Epoch [24/40],  Total loss : 0.0021\n",
            "Accuracy of the network on the 5000 validation images: 86.82 %\n",
            "Validation loss decreased (0.480284 --> 0.455339).  Saving model ...\n",
            "Epoch [25/40],  Total loss : 0.0021\n",
            "Accuracy of the network on the 5000 validation images: 86.34 %\n",
            "EarlyStopping counter: 1 out of 15\n",
            "Epoch [26/40],  Total loss : 0.0023\n",
            "Accuracy of the network on the 5000 validation images: 86.76 %\n",
            "EarlyStopping counter: 2 out of 15\n",
            "Epoch [27/40],  Total loss : 0.0024\n",
            "Accuracy of the network on the 5000 validation images: 86.8 %\n",
            "EarlyStopping counter: 3 out of 15\n",
            "Epoch [28/40],  Total loss : 0.0024\n",
            "Accuracy of the network on the 5000 validation images: 86.98 %\n",
            "Validation loss decreased (0.455339 --> 0.445130).  Saving model ...\n",
            "Epoch [29/40],  Total loss : 0.0025\n",
            "Accuracy of the network on the 5000 validation images: 86.84 %\n",
            "EarlyStopping counter: 1 out of 15\n",
            "Epoch [30/40],  Total loss : 0.0028\n",
            "Accuracy of the network on the 5000 validation images: 86.76 %\n",
            "EarlyStopping counter: 2 out of 15\n",
            "Epoch [31/40],  Total loss : 0.0026\n",
            "Accuracy of the network on the 5000 validation images: 87.16 %\n",
            "EarlyStopping counter: 3 out of 15\n",
            "Epoch [32/40],  Total loss : 0.0025\n",
            "Accuracy of the network on the 5000 validation images: 86.68 %\n",
            "Validation loss decreased (0.445130 --> 0.444230).  Saving model ...\n",
            "Epoch [33/40],  Total loss : 0.0025\n",
            "Accuracy of the network on the 5000 validation images: 86.64 %\n",
            "EarlyStopping counter: 1 out of 15\n",
            "Epoch [34/40],  Total loss : 0.0027\n",
            "Accuracy of the network on the 5000 validation images: 86.4 %\n",
            "EarlyStopping counter: 2 out of 15\n",
            "Epoch [35/40],  Total loss : 0.3479\n",
            "Accuracy of the network on the 5000 validation images: 81.18 %\n",
            "EarlyStopping counter: 3 out of 15\n",
            "Epoch [36/40],  Total loss : 0.2410\n",
            "Accuracy of the network on the 5000 validation images: 80.06 %\n",
            "EarlyStopping counter: 4 out of 15\n",
            "Epoch [37/40],  Total loss : 0.1378\n",
            "Accuracy of the network on the 5000 validation images: 81.76 %\n",
            "EarlyStopping counter: 5 out of 15\n",
            "Epoch [38/40],  Total loss : 0.0863\n",
            "Accuracy of the network on the 5000 validation images: 82.62 %\n",
            "EarlyStopping counter: 6 out of 15\n",
            "Epoch [39/40],  Total loss : 0.0562\n",
            "Accuracy of the network on the 5000 validation images: 83.88 %\n",
            "EarlyStopping counter: 7 out of 15\n",
            "Epoch [40/40],  Total loss : 0.0424\n",
            "Accuracy of the network on the 5000 validation images: 83.82 %\n",
            "EarlyStopping counter: 8 out of 15\n",
            "Elapsed time: 114.2018966515859 minutes\n",
            "\n",
            "\n",
            "\n",
            "Accuracy of the model on the test images: 86.32 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "veG1DwbGFSpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2 nodes 4 bits\n",
        "\n",
        "num_nodes = 2\n",
        "num_bits = 4\n",
        "# Model\n",
        "model = resnet18(num_classes).to(device)\n",
        "\n",
        "#Early stopping\n",
        "early_stopping = EarlyStopping(patience=15, verbose=True)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f'###########################################################################\\n')\n",
        "print(f'Running Resnet18 for {num_nodes} node(s) and {num_bits} quantization bits:')\n",
        "start = time.time()\n",
        "\n",
        "args = arguments(ef=error_feedback, two_phase=two_phase, n_bit=num_bits, c_dim=c_dim, random=random, no_cuda=no_cuda, num_users=num_nodes, scale=scale)\n",
        "quantizer = PSQuantizer(QSGDCompressor, model.parameters(), args)\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    average_validation_loss = train(train_loader, model, criterion, optimizer, epoch, num_nodes,  quantizer)\n",
        "\n",
        "    early_stopping(average_validation_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(f'Elapsed time: {(end - start) / 60} minutes')\n",
        "print(f'\\n\\n')\n",
        "# initialize the model\n",
        "model = resnet18(num_classes).to(device)\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iCQpwQmFRTp",
        "outputId": "e0576be6-d192-4d12-f787-edac0372c063"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###########################################################################\n",
            "\n",
            "Running Resnet18 for 2 node(s) and 4 quantization bits:\n",
            "Epoch [1/40],  Total loss : 1.4764\n",
            "Accuracy of the network on the 5000 validation images: 59.82 %\n",
            "Validation loss decreased (inf --> 1.095513).  Saving model ...\n",
            "Epoch [2/40],  Total loss : 0.9141\n",
            "Accuracy of the network on the 5000 validation images: 74.38 %\n",
            "Validation loss decreased (1.095513 --> 0.741983).  Saving model ...\n",
            "Epoch [3/40],  Total loss : 0.6692\n",
            "Accuracy of the network on the 5000 validation images: 77.2 %\n",
            "Validation loss decreased (0.741983 --> 0.684616).  Saving model ...\n",
            "Epoch [4/40],  Total loss : 0.5322\n",
            "Accuracy of the network on the 5000 validation images: 77.34 %\n",
            "Validation loss decreased (0.684616 --> 0.648937).  Saving model ...\n",
            "Epoch [5/40],  Total loss : 0.4337\n",
            "Accuracy of the network on the 5000 validation images: 80.52 %\n",
            "Validation loss decreased (0.648937 --> 0.584483).  Saving model ...\n",
            "Epoch [6/40],  Total loss : 0.3585\n",
            "Accuracy of the network on the 5000 validation images: 81.06 %\n",
            "Validation loss decreased (0.584483 --> 0.552938).  Saving model ...\n",
            "Epoch [7/40],  Total loss : 0.2763\n",
            "Accuracy of the network on the 5000 validation images: 81.26 %\n",
            "EarlyStopping counter: 1 out of 15\n",
            "Epoch [8/40],  Total loss : 0.2139\n",
            "Accuracy of the network on the 5000 validation images: 82.26 %\n",
            "Validation loss decreased (0.552938 --> 0.534514).  Saving model ...\n",
            "Epoch [9/40],  Total loss : 0.1758\n",
            "Accuracy of the network on the 5000 validation images: 81.64 %\n",
            "EarlyStopping counter: 1 out of 15\n",
            "Epoch [10/40],  Total loss : 0.1233\n",
            "Accuracy of the network on the 5000 validation images: 82.52 %\n",
            "EarlyStopping counter: 2 out of 15\n",
            "Epoch [11/40],  Total loss : 0.0953\n",
            "Accuracy of the network on the 5000 validation images: 82.54 %\n",
            "EarlyStopping counter: 3 out of 15\n",
            "Epoch [12/40],  Total loss : 0.0790\n",
            "Accuracy of the network on the 5000 validation images: 82.0 %\n",
            "EarlyStopping counter: 4 out of 15\n",
            "Epoch [13/40],  Total loss : 0.0617\n",
            "Accuracy of the network on the 5000 validation images: 83.9 %\n",
            "EarlyStopping counter: 5 out of 15\n",
            "Epoch [14/40],  Total loss : 0.0537\n",
            "Accuracy of the network on the 5000 validation images: 83.12 %\n",
            "EarlyStopping counter: 6 out of 15\n",
            "Epoch [15/40],  Total loss : 0.0469\n",
            "Accuracy of the network on the 5000 validation images: 83.12 %\n",
            "EarlyStopping counter: 7 out of 15\n",
            "Epoch [16/40],  Total loss : 0.0414\n",
            "Accuracy of the network on the 5000 validation images: 83.38 %\n",
            "EarlyStopping counter: 8 out of 15\n",
            "Epoch [17/40],  Total loss : 0.0212\n",
            "Accuracy of the network on the 5000 validation images: 84.2 %\n",
            "EarlyStopping counter: 9 out of 15\n",
            "Epoch [18/40],  Total loss : 0.0111\n",
            "Accuracy of the network on the 5000 validation images: 85.18 %\n",
            "EarlyStopping counter: 10 out of 15\n",
            "Epoch [19/40],  Total loss : 0.0050\n",
            "Accuracy of the network on the 5000 validation images: 86.06 %\n",
            "EarlyStopping counter: 11 out of 15\n",
            "Epoch [20/40],  Total loss : 0.0027\n",
            "Accuracy of the network on the 5000 validation images: 86.52 %\n",
            "Validation loss decreased (0.534514 --> 0.510065).  Saving model ...\n",
            "Epoch [21/40],  Total loss : 0.0023\n",
            "Accuracy of the network on the 5000 validation images: 86.56 %\n",
            "Validation loss decreased (0.510065 --> 0.489623).  Saving model ...\n",
            "Epoch [22/40],  Total loss : 0.0021\n",
            "Accuracy of the network on the 5000 validation images: 86.68 %\n",
            "EarlyStopping counter: 1 out of 15\n",
            "Epoch [23/40],  Total loss : 0.0021\n",
            "Accuracy of the network on the 5000 validation images: 86.5 %\n",
            "Validation loss decreased (0.489623 --> 0.456949).  Saving model ...\n",
            "Epoch [24/40],  Total loss : 0.0022\n",
            "Accuracy of the network on the 5000 validation images: 86.5 %\n",
            "Validation loss decreased (0.456949 --> 0.453668).  Saving model ...\n",
            "Epoch [25/40],  Total loss : 0.0024\n",
            "Accuracy of the network on the 5000 validation images: 86.98 %\n",
            "Validation loss decreased (0.453668 --> 0.450373).  Saving model ...\n",
            "Epoch [26/40],  Total loss : 0.0024\n",
            "Accuracy of the network on the 5000 validation images: 86.88 %\n",
            "EarlyStopping counter: 1 out of 15\n",
            "Epoch [27/40],  Total loss : 0.0025\n",
            "Accuracy of the network on the 5000 validation images: 86.92 %\n",
            "EarlyStopping counter: 2 out of 15\n",
            "Epoch [28/40],  Total loss : 0.0026\n",
            "Accuracy of the network on the 5000 validation images: 86.56 %\n",
            "Validation loss decreased (0.450373 --> 0.444720).  Saving model ...\n",
            "Epoch [29/40],  Total loss : 0.0026\n",
            "Accuracy of the network on the 5000 validation images: 86.9 %\n",
            "EarlyStopping counter: 1 out of 15\n",
            "Epoch [30/40],  Total loss : 0.0026\n",
            "Accuracy of the network on the 5000 validation images: 86.76 %\n",
            "Validation loss decreased (0.444720 --> 0.433604).  Saving model ...\n",
            "Epoch [31/40],  Total loss : 0.0026\n",
            "Accuracy of the network on the 5000 validation images: 86.64 %\n",
            "EarlyStopping counter: 1 out of 15\n",
            "Epoch [32/40],  Total loss : 0.0026\n",
            "Accuracy of the network on the 5000 validation images: 86.76 %\n",
            "EarlyStopping counter: 2 out of 15\n",
            "Epoch [33/40],  Total loss : 0.0026\n",
            "Accuracy of the network on the 5000 validation images: 86.88 %\n",
            "EarlyStopping counter: 3 out of 15\n",
            "Epoch [34/40],  Total loss : 0.0025\n",
            "Accuracy of the network on the 5000 validation images: 86.82 %\n",
            "EarlyStopping counter: 4 out of 15\n",
            "Epoch [35/40],  Total loss : 0.0025\n",
            "Accuracy of the network on the 5000 validation images: 86.38 %\n",
            "EarlyStopping counter: 5 out of 15\n",
            "Epoch [36/40],  Total loss : 0.0028\n",
            "Accuracy of the network on the 5000 validation images: 86.02 %\n",
            "EarlyStopping counter: 6 out of 15\n",
            "Epoch [37/40],  Total loss : 0.4147\n",
            "Accuracy of the network on the 5000 validation images: 80.56 %\n",
            "EarlyStopping counter: 7 out of 15\n",
            "Epoch [38/40],  Total loss : 0.2666\n",
            "Accuracy of the network on the 5000 validation images: 82.46 %\n",
            "EarlyStopping counter: 8 out of 15\n",
            "Epoch [39/40],  Total loss : 0.1423\n",
            "Accuracy of the network on the 5000 validation images: 81.84 %\n",
            "EarlyStopping counter: 9 out of 15\n",
            "Epoch [40/40],  Total loss : 0.1012\n",
            "Accuracy of the network on the 5000 validation images: 82.98 %\n",
            "EarlyStopping counter: 10 out of 15\n",
            "Elapsed time: 122.51801056861878 minutes\n",
            "\n",
            "\n",
            "\n",
            "Accuracy of the model on the test images: 87.15 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 nodes 8 bits"
      ],
      "metadata": {
        "id": "OOkVqKI5FpB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2 nodes 8 bits\n",
        "\n",
        "num_nodes = 2\n",
        "num_bits = 8\n",
        "# Model\n",
        "model = resnet18(num_classes).to(device)\n",
        "\n",
        "#Early stopping\n",
        "early_stopping = EarlyStopping(patience=17, verbose=True)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f'###########################################################################\\n')\n",
        "print(f'Running Resnet18 for {num_nodes} node(s) and {num_bits} quantization bits:')\n",
        "start = time.time()\n",
        "\n",
        "args = arguments(ef=error_feedback, two_phase=two_phase, n_bit=num_bits, c_dim=c_dim, random=random, no_cuda=no_cuda, num_users=num_nodes, scale=scale)\n",
        "quantizer = PSQuantizer(QSGDCompressor, model.parameters(), args)\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    average_validation_loss = train(train_loader, model, criterion, optimizer, epoch, num_nodes,  quantizer)\n",
        "\n",
        "    early_stopping(average_validation_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(f'Elapsed time: {(end - start) / 60} minutes')\n",
        "print(f'\\n\\n')\n",
        "# initialize the model\n",
        "model = resnet18(num_classes).to(device)\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45xScbJy9Gbe",
        "outputId": "50254bda-629b-4760-edaf-a1f6504b0d19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###########################################################################\n",
            "\n",
            "Running Resnet18 for 2 node(s) and 8 quantization bits:\n",
            "Epoch [1/40],  Total loss : 1.5110\n",
            "Accuracy of the network on the 5000 validation images: 59.62 %\n",
            "Validation loss decreased (inf --> 1.117321).  Saving model ...\n",
            "Epoch [2/40],  Total loss : 0.9354\n",
            "Accuracy of the network on the 5000 validation images: 70.34 %\n",
            "Validation loss decreased (1.117321 --> 0.832653).  Saving model ...\n",
            "Epoch [3/40],  Total loss : 0.6936\n",
            "Accuracy of the network on the 5000 validation images: 76.66 %\n",
            "Validation loss decreased (0.832653 --> 0.664794).  Saving model ...\n",
            "Epoch [4/40],  Total loss : 0.5472\n",
            "Accuracy of the network on the 5000 validation images: 79.54 %\n",
            "Validation loss decreased (0.664794 --> 0.603012).  Saving model ...\n",
            "Epoch [5/40],  Total loss : 0.4516\n",
            "Accuracy of the network on the 5000 validation images: 81.98 %\n",
            "Validation loss decreased (0.603012 --> 0.553483).  Saving model ...\n",
            "Epoch [6/40],  Total loss : 0.3638\n",
            "Accuracy of the network on the 5000 validation images: 81.9 %\n",
            "EarlyStopping counter: 1 out of 17\n",
            "Epoch [7/40],  Total loss : 0.2791\n",
            "Accuracy of the network on the 5000 validation images: 81.8 %\n",
            "EarlyStopping counter: 2 out of 17\n",
            "Epoch [8/40],  Total loss : 0.2298\n",
            "Accuracy of the network on the 5000 validation images: 82.46 %\n",
            "EarlyStopping counter: 3 out of 17\n",
            "Epoch [9/40],  Total loss : 0.1627\n",
            "Accuracy of the network on the 5000 validation images: 81.76 %\n",
            "EarlyStopping counter: 4 out of 17\n",
            "Epoch [10/40],  Total loss : 0.1291\n",
            "Accuracy of the network on the 5000 validation images: 82.84 %\n",
            "EarlyStopping counter: 5 out of 17\n",
            "Epoch [11/40],  Total loss : 0.0992\n",
            "Accuracy of the network on the 5000 validation images: 83.14 %\n",
            "EarlyStopping counter: 6 out of 17\n",
            "Epoch [12/40],  Total loss : 0.0703\n",
            "Accuracy of the network on the 5000 validation images: 83.88 %\n",
            "EarlyStopping counter: 7 out of 17\n",
            "Epoch [13/40],  Total loss : 0.0591\n",
            "Accuracy of the network on the 5000 validation images: 83.36 %\n",
            "EarlyStopping counter: 8 out of 17\n",
            "Epoch [14/40],  Total loss : 0.0496\n",
            "Accuracy of the network on the 5000 validation images: 83.94 %\n",
            "EarlyStopping counter: 9 out of 17\n",
            "Epoch [15/40],  Total loss : 0.0425\n",
            "Accuracy of the network on the 5000 validation images: 83.72 %\n",
            "EarlyStopping counter: 10 out of 17\n",
            "Epoch [16/40],  Total loss : 0.0318\n",
            "Accuracy of the network on the 5000 validation images: 83.7 %\n",
            "EarlyStopping counter: 11 out of 17\n",
            "Epoch [17/40],  Total loss : 0.0356\n",
            "Accuracy of the network on the 5000 validation images: 83.6 %\n",
            "EarlyStopping counter: 12 out of 17\n",
            "Epoch [18/40],  Total loss : 0.0196\n",
            "Accuracy of the network on the 5000 validation images: 85.02 %\n",
            "EarlyStopping counter: 13 out of 17\n",
            "Epoch [19/40],  Total loss : 0.0090\n",
            "Accuracy of the network on the 5000 validation images: 85.52 %\n",
            "EarlyStopping counter: 14 out of 17\n",
            "Epoch [20/40],  Total loss : 0.0039\n",
            "Accuracy of the network on the 5000 validation images: 86.1 %\n",
            "Validation loss decreased (0.553483 --> 0.511919).  Saving model ...\n",
            "Epoch [21/40],  Total loss : 0.0024\n",
            "Accuracy of the network on the 5000 validation images: 86.5 %\n",
            "Validation loss decreased (0.511919 --> 0.499630).  Saving model ...\n",
            "Epoch [22/40],  Total loss : 0.0020\n",
            "Accuracy of the network on the 5000 validation images: 86.84 %\n",
            "Validation loss decreased (0.499630 --> 0.481143).  Saving model ...\n",
            "Epoch [23/40],  Total loss : 0.0020\n",
            "Accuracy of the network on the 5000 validation images: 86.76 %\n",
            "Validation loss decreased (0.481143 --> 0.460851).  Saving model ...\n",
            "Epoch [24/40],  Total loss : 0.0021\n",
            "Accuracy of the network on the 5000 validation images: 86.52 %\n",
            "EarlyStopping counter: 1 out of 17\n",
            "Epoch [25/40],  Total loss : 0.0023\n",
            "Accuracy of the network on the 5000 validation images: 87.12 %\n",
            "Validation loss decreased (0.460851 --> 0.434604).  Saving model ...\n",
            "Epoch [26/40],  Total loss : 0.0023\n",
            "Accuracy of the network on the 5000 validation images: 86.44 %\n",
            "EarlyStopping counter: 1 out of 17\n",
            "Epoch [27/40],  Total loss : 0.0024\n",
            "Accuracy of the network on the 5000 validation images: 86.92 %\n",
            "Validation loss decreased (0.434604 --> 0.433598).  Saving model ...\n",
            "Epoch [28/40],  Total loss : 0.0024\n",
            "Accuracy of the network on the 5000 validation images: 86.86 %\n",
            "EarlyStopping counter: 1 out of 17\n",
            "Epoch [29/40],  Total loss : 0.0025\n",
            "Accuracy of the network on the 5000 validation images: 86.9 %\n",
            "EarlyStopping counter: 2 out of 17\n",
            "Epoch [30/40],  Total loss : 0.0027\n",
            "Accuracy of the network on the 5000 validation images: 86.5 %\n",
            "EarlyStopping counter: 3 out of 17\n",
            "Epoch [31/40],  Total loss : 0.0026\n",
            "Accuracy of the network on the 5000 validation images: 87.18 %\n",
            "EarlyStopping counter: 4 out of 17\n",
            "Epoch [32/40],  Total loss : 0.0025\n",
            "Accuracy of the network on the 5000 validation images: 86.88 %\n",
            "EarlyStopping counter: 5 out of 17\n",
            "Epoch [33/40],  Total loss : 0.0025\n",
            "Accuracy of the network on the 5000 validation images: 86.94 %\n",
            "EarlyStopping counter: 6 out of 17\n",
            "Epoch [34/40],  Total loss : 0.0025\n",
            "Accuracy of the network on the 5000 validation images: 86.52 %\n",
            "EarlyStopping counter: 7 out of 17\n",
            "Epoch [35/40],  Total loss : 0.2864\n",
            "Accuracy of the network on the 5000 validation images: 80.14 %\n",
            "EarlyStopping counter: 8 out of 17\n",
            "Epoch [36/40],  Total loss : 0.2650\n",
            "Accuracy of the network on the 5000 validation images: 82.08 %\n",
            "EarlyStopping counter: 9 out of 17\n",
            "Epoch [37/40],  Total loss : 0.1437\n",
            "Accuracy of the network on the 5000 validation images: 82.2 %\n",
            "EarlyStopping counter: 10 out of 17\n",
            "Epoch [38/40],  Total loss : 0.0833\n",
            "Accuracy of the network on the 5000 validation images: 84.32 %\n",
            "EarlyStopping counter: 11 out of 17\n",
            "Epoch [39/40],  Total loss : 0.0489\n",
            "Accuracy of the network on the 5000 validation images: 83.88 %\n",
            "EarlyStopping counter: 12 out of 17\n",
            "Epoch [40/40],  Total loss : 0.0373\n",
            "Accuracy of the network on the 5000 validation images: 83.44 %\n",
            "EarlyStopping counter: 13 out of 17\n",
            "Elapsed time: 175.46034664312998 minutes\n",
            "\n",
            "\n",
            "\n",
            "Accuracy of the model on the test images: 87.06 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KG8SJDMl2vzY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}